from fastapi import FastAPI, Request, UploadFile, File, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
import os, subprocess, csv, json
from pathlib import Path
from typing import List, Dict

# ADD sessions
import uuid, subprocess, json, re

app = FastAPI()

UPLOAD_DIR = Path("src/uploads")
OUTPUT_DIR = Path("src/outputs")    # ìƒì„±ë¬¼ì´ ì €ì¥ë˜ëŠ” í´ë”
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)



# === Add: path â†’ /outputs URL ë§¤í•‘ ìœ í‹¸ ===
# [ADD] ë‹¨ê³„(íˆ´)ë³„ ìƒíƒœÂ·ì•„í‹°íŒ©íŠ¸ ì •ë¦¬ ìœ í‹¸
import re




# ADD
# íŒŒì¼ ìƒë‹¨ import ì•„ë˜ì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).resolve().parent
NPX = "npx.cmd" if os.name == "nt" else "npx"

def run_ts_workflow(file_path: Path, filename: str, message: str = "ë¶„ì„í•´ì¤˜"):
    import shlex, subprocess, os
    base_args = [NPX, "ts-node", "src/main.ts", message, str(file_path), filename]
    env = os.environ.copy()
    try:
        # ê¶Œì¥: shell=False + cwd ì§€ì •
        proc = subprocess.Popen(
            base_args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            shell=False, text=True, encoding="utf-8", errors="replace",
            cwd=str(PROJECT_ROOT), env=env
        )
        stdout, stderr = proc.communicate(timeout=600)
        return proc.returncode, stdout, stderr
    except FileNotFoundError:
        # í´ë°±: shell=True ë¬¸ìì—´
        cmd_str = f'{NPX} ts-node src/main.ts {shlex.quote(message)} {shlex.quote(str(file_path))} {shlex.quote(filename)}'
        proc = subprocess.Popen(
            cmd_str, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            shell=True, text=True, encoding="utf-8", errors="replace",
            cwd=str(PROJECT_ROOT), env=env
        )
        stdout, stderr = proc.communicate(timeout=600)
        return proc.returncode, stdout, stderr


def _norm(p: str) -> str:
    return str(p).replace("\\", "/")

def path_to_outputs_url(path: str | None) -> str | None:
    if not path:
        return None
    p = Path(path)
    try:
        rel = p.relative_to(OUTPUT_DIR)
        return f"/outputs/{_norm(rel)}"
    except Exception:
        return f"/outputs/{_norm(p.name)}"

def map_artifacts(workflow: dict) -> dict:
    if not isinstance(workflow, dict):
        return workflow
    wf = dict(workflow)

    if wf.get("preprocessedFilePath"):
        wf["preprocessedFilePathUrl"] = path_to_outputs_url(wf["preprocessedFilePath"])

    mlp = dict(wf.get("mlResultPath") or {})
    if mlp.get("mlResultPath"):
        mlp["mlResultUrl"] = path_to_outputs_url(mlp["mlResultPath"])
    if mlp.get("reportPath"):
        mlp["reportUrl"] = path_to_outputs_url(mlp["reportPath"])
        # ë³´ê³ ì„œ í…ìŠ¤íŠ¸ê°€ ê¹¨ì¡Œìœ¼ë©´ UTF-8ë¡œ ì¬ì½ê¸° ì‹œë„
        if mlp.get("report") and "ï¿½" in mlp["report"]:
            try:
                mlp["report"] = Path(mlp["reportPath"]).read_text(encoding="utf-8", errors="ignore")
            except Exception:
                pass
    wf["mlResultPath"] = mlp

    if isinstance(wf.get("chartPaths"), list):
        wf["chartUrls"] = [path_to_outputs_url(p) for p in wf["chartPaths"]]
    return wf

def build_steps(wf: dict) -> list[dict]:
    """ì›Œí¬í”Œë¡œ dictì—ì„œ ë‹¨ê³„(íˆ´)ë³„ ì™„ë£Œ ì—¬ë¶€ë¥¼ ê³„ì‚°"""
    def st(key, title, ok):
        return {"key": key, "title": title, "status": "done" if ok else "skipped"}

    steps = []
    steps.append(st("basic",     "1) BasicAnalysisTool",            bool(wf.get("columnStats"))))
    steps.append(st("selector",  "2) SelectorTool",                 bool(wf.get("selectedColumns") or wf.get("recommendedPairs") or wf.get("preprocessingRecommendations"))))
    steps.append(st("visual",    "3) VisualizationTool",            bool(wf.get("chartUrls"))))
    steps.append(st("preprocess","4) PreprocessExecutorTool",       bool(wf.get("preprocessedFilePathUrl"))))
    ml_ok = bool( (wf.get("mlModelRecommendation") and wf["mlModelRecommendation"].get("model")) or
                  (wf.get("mlResultPath") and (wf["mlResultPath"].get("mlResultUrl") or wf["mlResultPath"].get("reportUrl"))) )
    steps.append(st("train",     "5) MachineLearningTool",          ml_ok))
    return steps

def looks_like_dump(text: str) -> bool:
    if not text:
        return False
    needles = [
        "[WorkflowTool", "BasicAnalysisTool", "SelectorTool",
        "VisualizationTool", "Preprocess", "MachineLearning",
        "columnStats", "recommendedPairs", "preprocessedFilePath",
        "mlResultPath", "reportPath", "chartPaths", "dtype:", "column:"
    ]
    return any(n in text for n in needles) or len(text) > 600

def coerce_to_json(s: str):
    """
    ë¡œê·¸ì— ì—¬ëŸ¬ JSON-ìœ ì‚¬ ë¸”ë¡ì´ ì„ì—¬ ìˆì„ ë•Œ,
    - í‚¤ì›Œë“œ í¬í•¨ ë¸”ë¡(columnStats ë“±) ìš°ì„ 
    - ì—†ìœ¼ë©´ ê°€ì¥ í° ë¸”ë¡
    ì„ ê³¨ë¼ ë³´ì • í›„ json.loads ì‹œë„.
    """
    # 0) ì •ìƒ JSON ë¨¼ì €
    try:
        return json.loads(s)
    except Exception:
        pass

    if not s or "{" not in s or "}" not in s:
        return None

    # 1) ëª¨ë“  ìµœìƒìœ„ {â€¦} ë¸”ë¡ ì¶”ì¶œ (ë¬¸ìì—´/ì´ìŠ¤ì¼€ì´í”„ ì¸ì§€)
    blocks = []
    depth = 0
    in_str = False
    esc = False
    start = None
    for i, ch in enumerate(s):
        if in_str:
            if esc:
                esc = False
            elif ch == "\\":
                esc = True
            elif ch == '"':
                in_str = False
            continue
        if ch == '"':
            in_str = True
            continue
        if ch == "{":
            if depth == 0:
                start = i
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0 and start is not None:
                blocks.append(s[start:i+1])
                start = None

    if not blocks:
        return None

    # 2) í‚¤ì›Œë“œê°€ ë“¤ì–´ìˆëŠ” ë¸”ë¡ì„ ìš°ì„ , ì—†ìœ¼ë©´ ê¸¸ì´ìˆœ ë‚´ë¦¼ì°¨ìˆœ
    prefer = ("columnStats", "selectedColumns", "mlModelRecommendation", "mlResultPath")
    blocks.sort(key=lambda b: (any(k in b for k in prefer), len(b)), reverse=True)

    # 3) ê° ë¸”ë¡ì— ëŒ€í•´ ë³´ì • í›„ íŒŒì‹± ì‹œë„
    for core in blocks:
        try:
            # { key: ... } -> { "key": ... }
            core2 = re.sub(r'([,{]\s*)([A-Za-z_][A-Za-z0-9_]*)\s*:', r'\1"\2":', core)
            # ' -> "
            core2 = core2.replace("'", '"')
            # JS íŠ¹ìˆ˜ê°’ â†’ JSON ê°’
            core2 = core2.replace("undefined", "null")
            core2 = re.sub(r'\bNaN\b', 'null', core2)
            core2 = re.sub(r'\bInfinity\b', 'null', core2)
            core2 = re.sub(r'\b-Infinity\b', 'null', core2)
            # [Object] â†’ {}
            core2 = re.sub(r'\[\s*Object\s*\]', "{}", core2)
            core2 = core2.replace("[Object], [Object]", "{}, {}")
            # ë ì½¤ë§ˆ ì œê±°
            core2 = re.sub(r',\s*([}\]])', r'\1', core2)
            return json.loads(core2)
        except Exception:
            continue

    return None

import re, time, json
ANSI_RE = re.compile(r"\x1b\[[0-9;]*m")

def sanitize_stdout(s: str) -> str:
    if not s: return ""
    return ANSI_RE.sub("", s).strip()

def _looks_like_workflow(obj: dict) -> bool:
    """ì›Œí¬í”Œë¡œ í•µì‹¬ í‚¤ê°€ 1ê°œë¼ë„ ìˆì–´ì•¼ ìœ íš¨ë¡œ ê°„ì£¼"""
    if not isinstance(obj, dict):
        return False
    keys = {
        "columnStats", "selectedColumns", "recommendedPairs",
        "preprocessingRecommendations", "preprocessedFilePath",
        "preprocessedFilePathUrl", "mlModelRecommendation",
        "mlResultPath", "chartPaths", "chartUrls"
    }
    return any(k in obj for k in keys)

def _jsonify_js_like(text: str) -> str:
    """JSí’ ê°ì²´/ë°°ì—´ ë¬¸ìì—´ì„ JSONìœ¼ë¡œ ê·¼ì‚¬ ë³€í™˜"""
    s = text
    # í‚¤ì— ìŒë”°ì˜´í‘œ ì—†ìœ¼ë©´ ì¶”ê°€: { key: ... } => { "key": ... }
    s = re.sub(r'([{\[,]\s*)([A-Za-z_][A-Za-z0-9_]*)\s*:', r'\1"\2":', s)
    # ' -> "
    s = s.replace("'", '"')
    # NaN/Infinity ê³„ì—´
    s = re.sub(r'\bNaN\b', 'null', s)
    s = re.sub(r'\b-Infinity\b', 'null', s)
    s = re.sub(r'\bInfinity\b', 'null', s)
    # ë ì½¤ë§ˆ ì œê±°
    s = re.sub(r',\s*([}\]])', r'\1', s)
    return s

def extract_workflow_dict(output_str: str):
    """
    1) coerce_to_json
    2) ```json ... ``` ì½”ë“œë¸”ë¡
    3) ìµœìƒìœ„ JSONì˜ answers[*].message.content ë‚´ë¶€ JSON
    4) ë¡œê·¸ í…ìŠ¤íŠ¸ì˜ 'BasicAnalysisTool ê²°ê³¼: [ ... ]' íŒ¨í„´ ì¬êµ¬ì„± â†’ {'columnStats': [...]}
    ì‹¤íŒ¨ ì‹œ (None, None)
    """
    s = sanitize_stdout(output_str)

    m = re.search(r"<<<WORKFLOW_JSON_START>>>\s*([\s\S]*?)\s*<<<WORKFLOW_JSON_END>>>", s)
    if m:
        try:
            obj = json.loads(m.group(1))
            cand = obj.get("workflow") if isinstance(obj, dict) else None
            if isinstance(cand, dict):
                return cand, obj
        except Exception:
            pass


    # 1) 1ì°¨: ê¸°ì¡´ ë³´ì • íŒŒì„œ
    top = coerce_to_json(s)
    if isinstance(top, dict):
        for cand in (top.get("workflow"), top.get("result"), top):
            if isinstance(cand, dict) and _looks_like_workflow(cand):
                return cand, top

    # 2) ```json ... ``` ì½”ë“œë¸”ë¡
    for m in re.finditer(r"```(?:json)?\s*([\s\S]*?)```", s, re.I):
        block = m.group(1).strip()
        try:
            obj = json.loads(block)
            for cand in (obj.get("workflow"), obj.get("result"), obj):
                if isinstance(cand, dict) and _looks_like_workflow(cand):
                    return cand, obj
        except Exception:
            pass

    # 3) answers[*].message.content ë‚´ë¶€ JSON
    try:
        maybe = json.loads(s)
        if isinstance(maybe, dict):
            for a in (maybe.get("answers") or []):
                content = ((a.get("message") or {}).get("content") or "").strip()
                if not content:
                    continue
                try:
                    obj = json.loads(content)
                except Exception:
                    obj = coerce_to_json(content.replace('\\"','"'))
                if isinstance(obj, dict):
                    for cand in (obj.get("workflow"), obj.get("result"), obj):
                        if isinstance(cand, dict) and _looks_like_workflow(cand):
                            return cand, obj
    except Exception:
        pass

    # 4) ë¡œê·¸ í…ìŠ¤íŠ¸ì—ì„œ BasicAnalysisTool ë°°ì—´ë§Œì´ë¼ë„ ì¶”ì¶œ
    m = re.search(r"BasicAnalysisTool\s*ê²°ê³¼\s*:\s*(\[[\s\S]*?\])", s, re.I)
    if m:
        arr_text = _jsonify_js_like(m.group(1))
        try:
            arr = json.loads(arr_text)
            if isinstance(arr, list) and arr and isinstance(arr[0], dict):
                wf = {"columnStats": arr}
                return wf, {"columnStats": arr}
        except Exception:
            pass

    return None, None


# ------------------------------
# ìƒì„±ë¬¼ ë¦¬ìŠ¤íŠ¸
# ------------------------------
def list_generated_files() -> List[Dict]:
    """OUTPUT_DIR ë‚´ ìƒì„±ë¬¼ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ dict ëª©ë¡ìœ¼ë¡œ ë°˜í™˜"""
    files = []
    if OUTPUT_DIR.exists():
        for p in sorted(OUTPUT_DIR.glob("*")):
            if p.is_file():
                files.append({
                    "name": p.name,
                    "url": f"/outputs/{p.name}",
                    "size": p.stat().st_size,
                    "ext": p.suffix.lower(),
                })
    return files


# Templates ì„¤ì •
templates = Jinja2Templates(directory="templates")

# CORS ì„¤ì • (í•„ìš” ì—†ìœ¼ë©´ ì‚­ì œí•´ë„ ë¨)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------------------
# CSV ë¯¸ë¦¬ë³´ê¸°
# ------------------------------
def get_csv_preview(file_path: str):
    head_columns, head_rows = [], []
    describe_columns, describe_rows = [], []

    try:
        import pandas as pd
        df = pd.read_csv(file_path)
        head_rows = df.head().to_dict(orient="records")
        head_columns = df.columns.tolist()

        describe_df = df.describe(include="all").reset_index()
        describe_rows = describe_df.to_dict(orient="records")
        describe_columns = describe_df.columns.tolist()
    except Exception as e:
        print(f"CSV ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")

    return head_columns, head_rows, describe_columns, describe_rows


# ìƒì„±ë¬¼ í´ë”ë¥¼ /outputs ê²½ë¡œë¡œ ì •ì  ì„œë¹™
app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")

# ------------------------------
# ì„¸ì…˜ ê´€ë¦¬
# ------------------------------
session_files: Dict[str, str] = {}
chat_histories: Dict[str, List[Dict]] = {}

# ------------------------------
# í™ˆ
# ------------------------------
@app.get("/", response_class=HTMLResponse)
async def home(request: Request, sessionId: str = Query(None)):
    # ADD
    file_path = session_files.get(sessionId)
    chat_history = chat_histories.get(sessionId, [])
    
    head_columns = []
    head_rows = []
    describe_columns = []
    describe_rows = []

    # if filename:
    #     file_path = UPLOAD_DIR / filename
    #     try:
    #         with file_path.open(newline="", encoding="utf-8") as csvfile:
    #             reader = csv.DictReader(csvfile)
    #             head_columns = reader.fieldnames or []
    #             for i, row in enumerate(reader):
    #                 if i >= 5:
    #                     break
    #                 head_rows.append(row)
    #     except Exception as e:
    #         print(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}")
    # if filename:
    #     file_path = UPLOAD_DIR / filename
    #     if file_path.exists():
    #         # âœ… pandas ê¸°ë°˜ ë¯¸ë¦¬ë³´ê¸° + ê¸°ìˆ í†µê³„
    #         head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))
    if file_path:
        head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(file_path)

    generated_files = list_generated_files()

    # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°ìš© ìƒì„±ë¬¼ (í™•ì¥ì ê¸°ì¤€)
    preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

    return templates.TemplateResponse("index.html", {
        "request": request,
        "head_columns": head_columns,
        "head_rows": head_rows,
        "describe_columns": describe_columns,
        "describe_rows": describe_rows,
        "current_filename": sessionId, # filename
        "generated_files": generated_files,
        "preview_images": preview_images,
    })


# ------------------------------
# CSV ì—…ë¡œë“œ
# ------------------------------
@app.post("/upload_csv/")
async def upload_csv(request: Request, file: UploadFile = File(...)):
    file_path = UPLOAD_DIR / file.filename
    with file_path.open("wb") as f:
        f.write(await file.read())

    # ADD filename ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    session_files[file.filename] = str(file_path)
    chat_histories[file.filename] = []
    head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))

    return templates.TemplateResponse("index.html", {
        "request": request,
        "current_filename": file.filename,
        "chat_history": chat_histories[file.filename],
        "workflow": None,
        "steps": [],
        "generated_files": list_generated_files(),
        "preview_images": [],
        "head_columns": head_columns,
        "head_rows": head_rows,
        "describe_columns": describe_columns,
        "describe_rows": describe_rows,
    })


# [ADD] ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ í•œ ë²ˆì— ì‹¤í–‰í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.post("/run_workflow/", response_class=HTMLResponse)
async def run_workflow(request: Request, filename: str = Form(None)):
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ë§Œ ë³´ì—¬ì¤Œ
    if not filename:
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ë¨¼ì € CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.",
            "current_filename": None, "generated_files": generated_files, "preview_images": preview_images,
            "workflow": None, "steps": [], "head_columns": [], "head_rows": [],
            "describe_columns": [], "describe_rows": [],
        })
    file_path = UPLOAD_DIR / filename
    if not file_path.exists():
        generated_files  = list_generated_files()
        preview_images = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "current_filename": filename, "generated_files": generated_files, "preview_images": preview_images,
            "workflow": None, "steps": [], "head_columns": [], "head_rows": [],
            "describe_columns": [], "describe_rows": [],
        })

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    try:
        code, stdout, stderr = run_ts_workflow(file_path, filename, message="ë¶„ì„í•´ì¤˜")
        if code != 0:
            reply = f"âŒ ì˜¤ë¥˜: {stderr.strip() or 'unknown error'}"
            generated_files  = list_generated_files()
            preview_images  = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
            hc, hr, dc, dr = get_csv_preview(str(file_path))
            return templates.TemplateResponse("index.html", {
                "request": request, "reply": reply, "current_filename": filename,
                "generated_files": generated_files, "preview_images": preview_images, "workflow": None, "steps": [],
                "head_columns": hc, "head_rows": hr, "describe_columns": dc, "describe_rows": dr,
            })

        # JSON íŒŒì‹± â†’ ì¹´ë“œ ë°ì´í„° êµ¬ì„±
        output_str = (stdout or "").strip()
        wf_raw, _ = extract_workflow_dict(output_str)

        # (ì„ íƒ) íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìµœê·¼ ìƒì„± ì´ë¯¸ì§€ë¡œ ìµœì†Œ Visualization ì¹´ë“œë¼ë„ ë„ìš°ê¸°
        if not isinstance(wf_raw, dict):
            now = time.time()
            recent = []
            for p in OUTPUT_DIR.glob("*"):
                if p.is_file() and p.suffix.lower() in {".png",".jpg",".jpeg",".gif",".webp"}:
                    if now - p.stat().st_mtime <= 15:
                        recent.append(f"/outputs/{p.name}")
            if recent:
                wf_raw = {"chartPaths": recent}

        # ë§¤í•‘/ìŠ¤í… êµ¬ì„±
        workflow_mapped = map_artifacts(wf_raw) if isinstance(wf_raw, dict) else None
        steps = build_steps(workflow_mapped) if workflow_mapped else []

        # íŒŒì¼/ë¯¸ë¦¬ë³´ê¸°/ê¸°ìˆ í†µê³„
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        hc, hr, dc, dr = get_csv_preview(str(file_path))

        # í´ë°±: íŒŒì‹± ì‹¤íŒ¨í–ˆì§€ë§Œ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ìµœì†Œ Visualization ì¹´ë“œë¼ë„ í‘œì‹œ
        if not workflow_mapped and preview_images:
            workflow_mapped = {"chartUrls": [img["url"] for img in preview_images]}
            steps = build_steps(workflow_mapped)

        print("[WF] keys:", list((workflow_mapped or {}).keys()))


        return templates.TemplateResponse("index.html", {
            "request": request, "current_filename": filename,
            "generated_files": generated_files, "preview_images": preview_images,
            "workflow": workflow_mapped, "steps": steps,
            "head_columns": hc, "head_rows": hr, "describe_columns": dc, "describe_rows": dr,
        })

    except subprocess.TimeoutExpired:
        gf = list_generated_files()
        pv = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        hc, hr, dc, dr = get_csv_preview(str(file_path))
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼", "current_filename": filename,
            "generated_files": gf, "preview_images": pv,
            "workflow": None, "steps": [], "head_columns": hc, "head_rows": hr,
            "describe_columns": dc, "describe_rows": dr,
        })
# ------------------------------
# ì±„íŒ…
# ------------------------------
@app.post("/chat/", response_class=HTMLResponse)
async def chat(request: Request, message: str = Form(...), filename: str = Form(None)):
    # print(f"ì±„íŒ… ìš”ì²­: message={message}, filename={filename}")
    # # í•¨ìˆ˜ ìœ„ìª½ ì–´ë”˜ê°€ì— [ADD]
    # def _text(x):
    #     return x.decode("utf-8", "replace").strip() if isinstance(x, (bytes, bytearray)) else (x or "").strip()

    if not filename or filename not in session_files:
        reply = "âš ï¸ íŒŒì¼ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CSVë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        return templates.TemplateResponse("index.html", {"request": request, "reply": reply})

    
    file_path = session_files[filename]
    chat_history = chat_histories.get(filename, [])
    chat_history.append({"role": "user", "content": message})

    try:
        cmd = ["npx", "ts-node", "src/main.ts", message, file_path, filename]
        proc = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            shell=True
        )
        stdout, stderr = proc.communicate(timeout=600)
        output_str = stdout.decode("utf-8").strip()

        parsed_json = coerce_to_json(output_str)
        if parsed_json and "answers" in parsed_json:
            chat_history.append({"role": "bot", "content": "ğŸ‘‰ ì•„ë˜ ë‹¨ê³„ë³„ ì¹´ë“œì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”."})
        else:
            chat_history.append({"role": "bot", "content": output_str})

        chat_histories[filename] = chat_history

        head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(file_path)
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

        return templates.TemplateResponse("index.html", {
            "request": request,
            "chat_history": chat_history,
            "current_filename": filename,
            "head_columns": head_columns,
            "head_rows": head_rows,
            "describe_columns": describe_columns,
            "describe_rows": describe_rows,
            "generated_files": generated_files,
            "preview_images": preview_images,
        })

    except subprocess.TimeoutExpired:
        reply = "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"
        chat_history.append({"role": "bot", "content": reply})
        chat_histories[filename] = chat_history
        return templates.TemplateResponse("index.html", {
            "request": request,
            "chat_history": chat_history,
            "reply": reply,
            "current_filename": filename,
        })

    #     if proc.returncode != 0:
    #         reply = f"âŒ ì˜¤ë¥˜: {stderr.strip()}"
    #     else:
    #         try:
    #             output_str = (stdout or "").strip() 
    #             print("stdout decoded:", output_str)
    #             response_json = coerce_to_json(output_str)   # [MOD]
    #             if not response_json:
    #                 raise ValueError("json parse failed")

    #             chat_answers = response_json.get("answers", [])
    #             chat_history = [{"role": "user", "content": message}]
                
    #             for answer in chat_answers:
    #                 content = (answer.get("message") or {}).get("content", "")
    #                 if content and not looks_like_dump(content):
    #                     chat_history.append({"role": "bot", "content": content})
    #                 elif content:
    #                     chat_history.append({"role": "bot", "content": "ğŸ‘‰ ì•„ë˜ ë‹¨ê³„ë³„ ì¹´ë“œì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”."})

    #             generated_files = list_generated_files()
    #             preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

                
    #             # ========= [ADD] ì›Œí¬í”Œë¡œ ì¶”ì¶œ ë° ì‚°ì¶œë¬¼ URL ë§¤í•‘ =========
    #             workflow = None
    #             candidates = [
    #                 response_json.get("workflow"),
    #                 response_json.get("result"),
    #                 response_json,  # ìµœìƒìœ„ê°€ ê³§ ì›Œí¬í”Œë¡œì¼ ìˆ˜ë„ ìˆìŒ
    #             ]
    #             for cand in candidates:
    #                 if isinstance(cand, dict) and (
    #                     "columnStats" in cand or "mlModelRecommendation" in cand
    #                 ):
    #                     workflow = cand
    #                     break

    #             workflow_mapped = map_artifacts(workflow) if workflow else None
    #             # ========= [ADD] ë =========
                
    #             steps = build_steps(workflow_mapped) if workflow_mapped else []  # [ADD]
    #             if filename:
    #                 file_path = UPLOAD_DIR / filename
    #                 head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))
    #             else:
    #                 head_columns, head_rows, describe_columns, describe_rows = [], [], [], []

    #             return templates.TemplateResponse("index.html", {
    #                 "request": request,
    #                 "chat_history": chat_history,
    #                 "current_filename": filename,
    #                 "generated_files": generated_files,
    #                 "preview_images": preview_images,
    #                 # ========= [ADD] í…œí”Œë¦¿ì— ì›Œí¬í”Œë¡œ ì „ë‹¬ =========
    #                 "workflow": workflow_mapped,
    #                 "steps": steps,
    #                 "head_columns": head_columns,
    #                 "head_rows": head_rows,
    #                 "describe_columns": describe_columns,
    #                 "describe_rows": describe_rows,
    #                 # ============================================
    #             })

    #         except Exception:
    #             reply = f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:\n{(stdout or'').strip()}"


    #     generated_files = list_generated_files()
    #     preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]
    #     if filename:
    #         file_path = UPLOAD_DIR / filename
    #         head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))
    #     else:
    #         head_columns, head_rows, describe_columns, describe_rows = [], [], [], []


    #     return templates.TemplateResponse("index.html", {
    #         "request": request,
    #         "reply": reply,
    #         "current_filename": filename,
    #         "generated_files": generated_files,
    #         "preview_images": preview_images,
    #         # ========= [ADD] ì—ëŸ¬ ì‹œì—ë„ í‚¤ ì¡´ì¬í•˜ë„ë¡ =========
    #         "workflow": None,
    #         "steps": [],
    #         "head_columns": head_columns,
    #         "head_rows": head_rows,
    #         "describe_columns": describe_columns,
    #         "describe_rows": describe_rows,
    #         # ==============================================
    #     })

    # except subprocess.TimeoutExpired:
    #     generated_files = list_generated_files()
    #     preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

    #     return templates.TemplateResponse("index.html", {
    #         "request": request,
    #         "reply": "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼",
    #         "current_filename": filename,
    #         "generated_files": generated_files,
    #         "preview_images": preview_images,
    #         # ========= [ADD] ì—ëŸ¬ ì‹œì—ë„ í‚¤ ì¡´ì¬í•˜ë„ë¡ =========
    #         "workflow": None,
    #         "steps": [],
    #         # ==============================================
    #     })