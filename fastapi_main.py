from fastapi import FastAPI, Request, UploadFile, File, Form, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, RedirectResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from pathlib import Path
import uuid, subprocess, json, re
from typing import List, Dict

app = FastAPI()

# ------------------------------
# í´ë” ê²½ë¡œ ì„¤ì •
# ------------------------------
UPLOAD_DIR = Path("src/uploads")
OUTPUT_DIR = Path("src/outputs")
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# ------------------------------
# Jinja2 í…œí”Œë¦¿
# ------------------------------
templates = Jinja2Templates(directory="templates")

# ------------------------------
# CORS
# ------------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------------------
# ì •ì  íŒŒì¼
# ------------------------------
app.mount("/outputs", StaticFiles(directory=str(OUTPUT_DIR)), name="outputs")

# ------------------------------
# ì„¸ì…˜ ê´€ë¦¬
# ------------------------------
session_files: Dict[str, str] = {}
chat_histories: Dict[str, List[Dict]] = {}

# ------------------------------
# CSV ë¯¸ë¦¬ë³´ê¸°
# ------------------------------
def get_csv_preview(file_path: str):
    head_columns, head_rows = [], []
    describe_columns, describe_rows = [], []

    try:
        import pandas as pd
        df = pd.read_csv(file_path)
        head_rows = df.head().to_dict(orient="records")
        head_columns = df.columns.tolist()

        describe_df = df.describe(include="all").reset_index()
        describe_rows = describe_df.to_dict(orient="records")
        describe_columns = describe_df.columns.tolist()
    except Exception as e:
        print(f"CSV ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜: {e}")

    return head_columns, head_rows, describe_columns, describe_rows

# ------------------------------
# JSON ë³´ì •
# ------------------------------
def coerce_to_json(s: str):
    try:
        return json.loads(s)
    except Exception:
        pass
    if not s or "{" not in s or "}" not in s:
        return None

    blocks = []
    depth, in_str, esc, start = 0, False, False, None
    for i, ch in enumerate(s):
        if in_str:
            if esc:
                esc = False
            elif ch == "\\":
                esc = True
            elif ch == '"':
                in_str = False
            continue
        if ch == '"':
            in_str = True
            continue
        if ch == "{":
            if depth == 0:
                start = i
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0 and start is not None:
                blocks.append(s[start:i+1])
                start = None

    if not blocks:
        return None

    prefer = ("columnStats", "selectedColumns", "mlModelRecommendation", "mlResultPath")
    blocks.sort(key=lambda b: (any(k in b for k in prefer), len(b)), reverse=True)

    for core in blocks:
        try:
            core2 = re.sub(r'([,{]\s*)([A-Za-z_][A-Za-z0-9_]*)\s*:', r'\1"\2":', core)
            core2 = core2.replace("'", '"').replace("undefined", "null")
            core2 = re.sub(r'\bNaN\b', 'null', core2)
            core2 = re.sub(r'\bInfinity\b', 'null', core2)
            core2 = re.sub(r'\b-Infinity\b', 'null', core2)
            core2 = re.sub(r'\[\s*Object\s*\]', '{}', core2)
            core2 = core2.replace("[Object], [Object]", "{}, {}")
            core2 = re.sub(r',\s*([}\]])', r'\1', core2)
            return json.loads(core2)
        except Exception:
            continue
    return None

import re, time, json
ANSI_RE = re.compile(r"\x1b\[[0-9;]*m")

def sanitize_stdout(s: str) -> str:
    if not s: return ""
    return ANSI_RE.sub("", s).strip()

def _looks_like_workflow(obj: dict) -> bool:
    """ì›Œí¬í”Œë¡œ í•µì‹¬ í‚¤ê°€ 1ê°œë¼ë„ ìˆì–´ì•¼ ìœ íš¨ë¡œ ê°„ì£¼"""
    if not isinstance(obj, dict):
        return False
    keys = {
        "columnStats", "selectedColumns", "recommendedPairs",
        "preprocessingRecommendations", "preprocessedFilePath",
        "preprocessedFilePathUrl", "mlModelRecommendation",
        "mlResultPath", "chartPaths", "chartUrls"
    }
    return any(k in obj for k in keys)

def _jsonify_js_like(text: str) -> str:
    """JSí’ ê°ì²´/ë°°ì—´ ë¬¸ìì—´ì„ JSONìœ¼ë¡œ ê·¼ì‚¬ ë³€í™˜"""
    s = text
    # í‚¤ì— ìŒë”°ì˜´í‘œ ì—†ìœ¼ë©´ ì¶”ê°€: { key: ... } => { "key": ... }
    s = re.sub(r'([{\[,]\s*)([A-Za-z_][A-Za-z0-9_]*)\s*:', r'\1"\2":', s)
    # ' -> "
    s = s.replace("'", '"')
    # NaN/Infinity ê³„ì—´
    s = re.sub(r'\bNaN\b', 'null', s)
    s = re.sub(r'\b-Infinity\b', 'null', s)
    s = re.sub(r'\bInfinity\b', 'null', s)
    # ë ì½¤ë§ˆ ì œê±°
    s = re.sub(r',\s*([}\]])', r'\1', s)
    return s

def extract_workflow_dict(output_str: str):
    """
    1) coerce_to_json
    2) ```json ... ``` ì½”ë“œë¸”ë¡
    3) ìµœìƒìœ„ JSONì˜ answers[*].message.content ë‚´ë¶€ JSON
    4) ë¡œê·¸ í…ìŠ¤íŠ¸ì˜ 'BasicAnalysisTool ê²°ê³¼: [ ... ]' íŒ¨í„´ ì¬êµ¬ì„± â†’ {'columnStats': [...]}
    ì‹¤íŒ¨ ì‹œ (None, None)
    """
    s = sanitize_stdout(output_str)

    m = re.search(r"<<<WORKFLOW_JSON_START>>>\s*([\s\S]*?)\s*<<<WORKFLOW_JSON_END>>>", s)
    if m:
        try:
            obj = json.loads(m.group(1))
            cand = obj.get("workflow") if isinstance(obj, dict) else None
            if isinstance(cand, dict):
                return cand, obj
        except Exception:
            pass


    # 1) 1ì°¨: ê¸°ì¡´ ë³´ì • íŒŒì„œ
    top = coerce_to_json(s)
    if isinstance(top, dict):
        for cand in (top.get("workflow"), top.get("result"), top):
            if isinstance(cand, dict) and _looks_like_workflow(cand):
                return cand, top

    # 2) ```json ... ``` ì½”ë“œë¸”ë¡
    for m in re.finditer(r"```(?:json)?\s*([\s\S]*?)```", s, re.I):
        block = m.group(1).strip()
        try:
            obj = json.loads(block)
            for cand in (obj.get("workflow"), obj.get("result"), obj):
                if isinstance(cand, dict) and _looks_like_workflow(cand):
                    return cand, obj
        except Exception:
            pass

    # 3) answers[*].message.content ë‚´ë¶€ JSON
    try:
        maybe = json.loads(s)
        if isinstance(maybe, dict):
            for a in (maybe.get("answers") or []):
                content = ((a.get("message") or {}).get("content") or "").strip()
                if not content:
                    continue
                try:
                    obj = json.loads(content)
                except Exception:
                    obj = coerce_to_json(content.replace('\\"','"'))
                if isinstance(obj, dict):
                    for cand in (obj.get("workflow"), obj.get("result"), obj):
                        if isinstance(cand, dict) and _looks_like_workflow(cand):
                            return cand, obj
    except Exception:
        pass

    # 4) ë¡œê·¸ í…ìŠ¤íŠ¸ì—ì„œ BasicAnalysisTool ë°°ì—´ë§Œì´ë¼ë„ ì¶”ì¶œ
    m = re.search(r"BasicAnalysisTool\s*ê²°ê³¼\s*:\s*(\[[\s\S]*?\])", s, re.I)
    if m:
        arr_text = _jsonify_js_like(m.group(1))
        try:
            arr = json.loads(arr_text)
            if isinstance(arr, list) and arr and isinstance(arr[0], dict):
                wf = {"columnStats": arr}
                return wf, {"columnStats": arr}
        except Exception:
            pass

    return None, None


# ------------------------------
# ìƒì„±ë¬¼ ë¦¬ìŠ¤íŠ¸
# ------------------------------
def list_generated_files() -> List[dict]:
    files = []
    for p in sorted(OUTPUT_DIR.glob("*")):
        if p.is_file():
            files.append({
                "name": p.name,
                "url": f"/outputs/{p.name}",
                "size": p.stat().st_size,
                "ext": p.suffix.lower(),
            })
    return files

# ------------------------------
# í™ˆ
# ------------------------------
@app.get("/", response_class=HTMLResponse)
async def home(request: Request, sessionId: str = Query(None)):
    file_path = session_files.get(sessionId)
    chat_history = chat_histories.get(sessionId, [])

    head_columns, head_rows, describe_columns, describe_rows = [], [], [], []
    if file_path:
        head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(file_path)

    generated_files = list_generated_files()
    preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

    return templates.TemplateResponse("index.html", {
        "request": request,
        "chat_history": chat_history,
        "current_sessionId": sessionId,
        "head_columns": head_columns,
        "head_rows": head_rows,
        "describe_columns": describe_columns,
        "describe_rows": describe_rows,
        "generated_files": generated_files,
        "preview_images": preview_images,
    })

# ------------------------------
# CSV ì—…ë¡œë“œ
# ------------------------------
@app.post("/upload_csv/")
async def upload_csv(request: Request, file: UploadFile = File(...)):
    file_path = UPLOAD_DIR / file.filename
    with file_path.open("wb") as f:
        f.write(await file.read())

    # filename ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    session_files[file.filename] = str(file_path)
    chat_histories[file.filename] = []

    head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))

    return templates.TemplateResponse("index.html", {
        "request": request,
        "current_filename": file.filename,
        "chat_history": chat_histories[file.filename],
        "workflow": None,
        "steps": [],
        "generated_files": list_generated_files(),
        "preview_images": [],
        "head_columns": head_columns,
        "head_rows": head_rows,
        "describe_columns": describe_columns,
        "describe_rows": describe_rows,
    })


# [ADD] ì—…ë¡œë“œëœ íŒŒì¼ë¡œ ì›Œí¬í”Œë¡œìš°ë¥¼ í•œ ë²ˆì— ì‹¤í–‰í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.post("/run_workflow/", response_class=HTMLResponse)
async def run_workflow(request: Request, filename: str = Form(None)):
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ë§Œ ë³´ì—¬ì¤Œ
    if not filename:
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ë¨¼ì € CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.",
            "current_filename": None, "generated_files": generated_files, "preview_images": preview_images,
            "workflow": None, "steps": [], "head_columns": [], "head_rows": [],
            "describe_columns": [], "describe_rows": [],
        })
    file_path = UPLOAD_DIR / filename
    if not file_path.exists():
        generated_files  = list_generated_files()
        preview_images = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ì—…ë¡œë“œëœ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.",
            "current_filename": filename, "generated_files": generated_files, "preview_images": preview_images,
            "workflow": None, "steps": [], "head_columns": [], "head_rows": [],
            "describe_columns": [], "describe_rows": [],
        })

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    try:
        code, stdout, stderr = run_ts_workflow(file_path, filename, message="ë¶„ì„í•´ì¤˜")
        if code != 0:
            reply = f"âŒ ì˜¤ë¥˜: {stderr.strip() or 'unknown error'}"
            generated_files  = list_generated_files()
            preview_images  = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
            hc, hr, dc, dr = get_csv_preview(str(file_path))
            return templates.TemplateResponse("index.html", {
                "request": request, "reply": reply, "current_filename": filename,
                "generated_files": generated_files, "preview_images": preview_images, "workflow": None, "steps": [],
                "head_columns": hc, "head_rows": hr, "describe_columns": dc, "describe_rows": dr,
            })

        # JSON íŒŒì‹± â†’ ì¹´ë“œ ë°ì´í„° êµ¬ì„±
        output_str = (stdout or "").strip()
        wf_raw, _ = extract_workflow_dict(output_str)

        # (ì„ íƒ) íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìµœê·¼ ìƒì„± ì´ë¯¸ì§€ë¡œ ìµœì†Œ Visualization ì¹´ë“œë¼ë„ ë„ìš°ê¸°
        if not isinstance(wf_raw, dict):
            now = time.time()
            recent = []
            for p in OUTPUT_DIR.glob("*"):
                if p.is_file() and p.suffix.lower() in {".png",".jpg",".jpeg",".gif",".webp"}:
                    if now - p.stat().st_mtime <= 15:
                        recent.append(f"/outputs/{p.name}")
            if recent:
                wf_raw = {"chartPaths": recent}

        # ë§¤í•‘/ìŠ¤í… êµ¬ì„±
        workflow_mapped = map_artifacts(wf_raw) if isinstance(wf_raw, dict) else None
        steps = build_steps(workflow_mapped) if workflow_mapped else []

        # íŒŒì¼/ë¯¸ë¦¬ë³´ê¸°/ê¸°ìˆ í†µê³„
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        hc, hr, dc, dr = get_csv_preview(str(file_path))

        # í´ë°±: íŒŒì‹± ì‹¤íŒ¨í–ˆì§€ë§Œ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ìµœì†Œ Visualization ì¹´ë“œë¼ë„ í‘œì‹œ
        if not workflow_mapped and preview_images:
            workflow_mapped = {"chartUrls": [img["url"] for img in preview_images]}
            steps = build_steps(workflow_mapped)

        print("[WF] keys:", list((workflow_mapped or {}).keys()))


        return templates.TemplateResponse("index.html", {
            "request": request, "current_filename": filename,
            "generated_files": generated_files, "preview_images": preview_images,
            "workflow": workflow_mapped, "steps": steps,
            "head_columns": hc, "head_rows": hr, "describe_columns": dc, "describe_rows": dr,
        })

    except subprocess.TimeoutExpired:
        gf = list_generated_files()
        pv = [f for f in gf if f["ext"] in {".png",".jpg",".jpeg",".gif",".webp"}]
        hc, hr, dc, dr = get_csv_preview(str(file_path))
        return templates.TemplateResponse("index.html", {
            "request": request, "reply": "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼", "current_filename": filename,
            "generated_files": gf, "preview_images": pv,
            "workflow": None, "steps": [], "head_columns": hc, "head_rows": hr,
            "describe_columns": dc, "describe_rows": dr,
        })
# ------------------------------
# ì±„íŒ…
# ------------------------------
@app.post("/chat/", response_class=HTMLResponse)
async def chat(request: Request, message: str = Form(...), filename: str = Form(...)):
    if not filename or filename not in session_files:
        reply = "âš ï¸ íŒŒì¼ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CSVë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
        return templates.TemplateResponse("index.html", {"request": request, "reply": reply})

    file_path = session_files[filename]
    chat_history = chat_histories.get(filename, [])
    chat_history.append({"role": "user", "content": message})

    try:
        cmd = ["npx", "ts-node", "src/main.ts", message, file_path, filename]
        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
        stdout, stderr = proc.communicate(timeout=600)
        output_str = stdout.decode("utf-8").strip()

        parsed_json = coerce_to_json(output_str)
        if parsed_json and "answers" in parsed_json:
            chat_history.append({"role": "bot", "content": "ğŸ‘‰ ì•„ë˜ ë‹¨ê³„ë³„ ì¹´ë“œì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”."})
        else:
            chat_history.append({"role": "bot", "content": output_str})

        chat_histories[filename] = chat_history

        head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(file_path)
        generated_files = list_generated_files()
        preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

        return templates.TemplateResponse("index.html", {
            "request": request,
            "chat_history": chat_history,
            "current_filename": filename,
            "head_columns": head_columns,
            "head_rows": head_rows,
            "describe_columns": describe_columns,
            "describe_rows": describe_rows,
            "generated_files": generated_files,
            "preview_images": preview_images,
        })

    except subprocess.TimeoutExpired:
        reply = "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"
        chat_history.append({"role": "bot", "content": reply})
        chat_histories[filename] = chat_history
        return templates.TemplateResponse("index.html", {
            "request": request,
            "chat_history": chat_history,
            "reply": reply,
            "current_filename": filename,
        })

    #     if proc.returncode != 0:
    #         reply = f"âŒ ì˜¤ë¥˜: {stderr.strip()}"
    #     else:
    #         try:
    #             output_str = (stdout or "").strip() 
    #             print("stdout decoded:", output_str)
    #             response_json = coerce_to_json(output_str)   # [MOD]
    #             if not response_json:
    #                 raise ValueError("json parse failed")

    #             chat_answers = response_json.get("answers", [])
    #             chat_history = [{"role": "user", "content": message}]
                
    #             for answer in chat_answers:
    #                 content = (answer.get("message") or {}).get("content", "")
    #                 if content and not looks_like_dump(content):
    #                     chat_history.append({"role": "bot", "content": content})
    #                 elif content:
    #                     chat_history.append({"role": "bot", "content": "ğŸ‘‰ ì•„ë˜ ë‹¨ê³„ë³„ ì¹´ë“œì—ì„œ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”."})

    #             generated_files = list_generated_files()
    #             preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

                
    #             # ========= [ADD] ì›Œí¬í”Œë¡œ ì¶”ì¶œ ë° ì‚°ì¶œë¬¼ URL ë§¤í•‘ =========
    #             workflow = None
    #             candidates = [
    #                 response_json.get("workflow"),
    #                 response_json.get("result"),
    #                 response_json,  # ìµœìƒìœ„ê°€ ê³§ ì›Œí¬í”Œë¡œì¼ ìˆ˜ë„ ìˆìŒ
    #             ]
    #             for cand in candidates:
    #                 if isinstance(cand, dict) and (
    #                     "columnStats" in cand or "mlModelRecommendation" in cand
    #                 ):
    #                     workflow = cand
    #                     break

    #             workflow_mapped = map_artifacts(workflow) if workflow else None
    #             # ========= [ADD] ë =========
                
    #             steps = build_steps(workflow_mapped) if workflow_mapped else []  # [ADD]
    #             if filename:
    #                 file_path = UPLOAD_DIR / filename
    #                 head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))
    #             else:
    #                 head_columns, head_rows, describe_columns, describe_rows = [], [], [], []

    #             return templates.TemplateResponse("index.html", {
    #                 "request": request,
    #                 "chat_history": chat_history,
    #                 "current_filename": filename,
    #                 "generated_files": generated_files,
    #                 "preview_images": preview_images,
    #                 # ========= [ADD] í…œí”Œë¦¿ì— ì›Œí¬í”Œë¡œ ì „ë‹¬ =========
    #                 "workflow": workflow_mapped,
    #                 "steps": steps,
    #                 "head_columns": head_columns,
    #                 "head_rows": head_rows,
    #                 "describe_columns": describe_columns,
    #                 "describe_rows": describe_rows,
    #                 # ============================================
    #             })

    #         except Exception:
    #             reply = f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨:\n{(stdout or'').strip()}"


    #     generated_files = list_generated_files()
    #     preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]
    #     if filename:
    #         file_path = UPLOAD_DIR / filename
    #         head_columns, head_rows, describe_columns, describe_rows = get_csv_preview(str(file_path))
    #     else:
    #         head_columns, head_rows, describe_columns, describe_rows = [], [], [], []


    #     return templates.TemplateResponse("index.html", {
    #         "request": request,
    #         "reply": reply,
    #         "current_filename": filename,
    #         "generated_files": generated_files,
    #         "preview_images": preview_images,
    #         # ========= [ADD] ì—ëŸ¬ ì‹œì—ë„ í‚¤ ì¡´ì¬í•˜ë„ë¡ =========
    #         "workflow": None,
    #         "steps": [],
    #         "head_columns": head_columns,
    #         "head_rows": head_rows,
    #         "describe_columns": describe_columns,
    #         "describe_rows": describe_rows,
    #         # ==============================================
    #     })

    # except subprocess.TimeoutExpired:
    #     generated_files = list_generated_files()
    #     preview_images = [f for f in generated_files if f["ext"] in {".png", ".jpg", ".jpeg", ".gif", ".webp"}]

    #     return templates.TemplateResponse("index.html", {
    #         "request": request,
    #         "reply": "âš ï¸ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼",
    #         "current_filename": filename,
    #         "generated_files": generated_files,
    #         "preview_images": preview_images,
    #         # ========= [ADD] ì—ëŸ¬ ì‹œì—ë„ í‚¤ ì¡´ì¬í•˜ë„ë¡ =========
    #         "workflow": None,
    #         "steps": [],
    #         # ==============================================
    #     })