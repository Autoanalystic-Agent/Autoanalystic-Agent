// agentica ë¶ˆëŸ¬ì˜¤ê¸°
import { Agentica } from "@agentica/core";
import { OpenAI } from "openai";

// íˆ´
import { BasicAnalysisTool } from "./tools/BasicAnalysisTool";
import { CorrelationTool } from "./tools/CorrelationTool";
import { SelectorTool } from "./tools/SelectorTool";
import { VisualizationTool } from "./tools/VisualizationTool";
import { PreprocessingTool } from "./tools/PreprocessingTool";
import { WorkflowTool } from "./tools/WorkflowTool";
import { MachineLearningTool } from "./tools/MachineLearningTool";
// í•„ìš”ì‹œ CorrelationToolë„ import

// ê¸°íƒ€
import typia from "typia";
import readline from "readline";
import dotenv from "dotenv";
import fs from "fs";

const originalConsoleLog = console.log;
console.log = (...args: any[]) => {
  if (args[0]?.includes("injecting env")) return;
  originalConsoleLog(...args);
};

dotenv.config();

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// í•œêµ­ì–´ ê°•ì œ ê°€ë“œ
function isMostlyKorean(text: string, threshold = 0.4) {
  const hangul = (text.match(/[ê°€-í£]/g) || []).length;
  const letters = (text.match(/[A-Za-zê°€-í£]/g) || []).length || 1;
  return hangul / letters >= threshold;
}

async function forceKoreanOnly(openai: OpenAI, text: string): Promise<string> {
  const sys = `ë„ˆëŠ” í¸ì§‘ ë„ìš°ë¯¸ë‹¤. ê·œì¹™:
1) ì¶œë ¥ì€ í•œêµ­ì–´ ë¬¸ì¥ë§Œ. ì˜ì–´ ë¬¸ì¥/ì œëª© ê¸ˆì§€.
2) ì½”ë“œë¸”ë¡(\`\`\`)ê³¼ ì¸ë¼ì¸ ì½”ë“œ(\`...\`)ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ.
3) í‘œ(ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”)ëŠ” êµ¬ì¡° ìœ ì§€, ì…€ì˜ ìì—°ì–´ë§Œ í•œêµ­ì–´ë¡œ.
4) íŒŒì¼ ê²½ë¡œ/ì»¬ëŸ¼ëª…/í•¨ìˆ˜ëª…/ë§¤ê°œë³€ìˆ˜/í‚¤/ì—ëŸ¬í‚¤ì›Œë“œëŠ” ì›ë¬¸ ìœ ì§€ ê°€ëŠ¥.
5) ë¶ˆí•„ìš”í•œ ì„œë¡ /í›„ê¸° ê¸ˆì§€.`;
  const usr = `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìœ„ ê·œì¹™ìœ¼ë¡œ í•œêµ­ì–´ë§Œ ë‚¨ê¸°ê³  ì •ë¦¬í•´ì¤˜:\n\n${text}`;
  const resp = await openai.chat.completions.create({
    model: "gpt-4.1-mini",
    messages: [
      { role: "system", content: sys },
      { role: "user", content: usr },
    ],
    temperature: 0.2,
  });
  return resp.choices[0]?.message?.content?.trim() || text;
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ì„¸ì…˜ ë©”ëª¨ë¦¬ (ê°„ë‹¨ ë²„ì „)
type HistoryJson = any;
const SESSIONS = new Map<string, HistoryJson[]>();
function loadHistories(k: string) { return SESSIONS.get(k) ?? []; }
function saveHistories(k: string, prompts: any[]) {
  const prev = SESSIONS.get(k) ?? [];
  const delta = prompts
    .map((p) => (typeof p?.toJSON === "function" ? p.toJSON() : p))
    .filter((h: any) => h?.type === "text" || h?.type === "describe");
  SESSIONS.set(k, [...prev, ...delta]);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ì±„íŒ… ëª¨ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
const CHAT_SYSTEM = `
ë‹¹ì‹ ì€ CSV ë¶„ì„ ì±—ë´‡ì…ë‹ˆë‹¤.

ì–¸ì–´ ì •ì±…(ë§¤ìš° ì¤‘ìš”):
- ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ **í•œêµ­ì–´(ko-KR)** ë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤.
- ê³ ìœ ëª…ì‚¬/ì½”ë“œ/í•¨ìˆ˜ëª…/ì»¬ëŸ¼ëª…/íŒŒì¼ê²½ë¡œ/ë§¤ê°œë³€ìˆ˜/ì˜¤ë¥˜í‚¤ì›Œë“œ ë“±ì€ ì›ë¬¸ ìœ ì§€ ê°€ëŠ¥.
- ê·¸ ì™¸ ì„¤ëª…Â·í•´ì„¤Â·í‘œì œÂ·ìš”ì•½ì€ ì „ë¶€ í•œêµ­ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
- ì˜ì–´ ë¬¸ì¥ì´ë‚˜ ì˜ì–´ ì œëª©(ì˜ˆ: "Key Observations", "Summary")ì´ ì„ì˜€ë‹¤ê³  íŒë‹¨ë˜ë©´,
  ìŠ¤ìŠ¤ë¡œ í•œêµ­ì–´ë¡œ ì¦‰ì‹œ ë°”ë¡œì¡ì•„ ìµœì¢… ì¶œë ¥ì—ëŠ” í•œêµ­ì–´ë§Œ ë‚¨ê¸°ì„¸ìš”.

ì•„ë˜ ë„êµ¬ë¥¼ ìƒí™©ì— ë§ê²Œ ì‚¬ìš©í•´ í•œêµ­ì–´ë¡œ ê°„ê²°íˆ ë‹µí•˜ì„¸ìš”.
- BasicAnalysisTool: ì»¬ëŸ¼ ìš”ì•½/ê²°ì¸¡ì¹˜/ê¸°ì´ˆí†µê³„
- SelectorTool: ì»¬ëŸ¼ ì¶”ì²œ/í˜ì–´ ì¶”ì²œ/ì „ì²˜ë¦¬ ê¶Œê³ 
- CorrelationTool: ìƒê´€ê³„ìˆ˜/ë‹¤ì¤‘ê³µì„ ì„±/íˆíŠ¸ë§µ
- VisualizationTool: ë‹¨/ì´ë³€ëŸ‰ ì‹œê°í™”
- PreprocessingTool: ê²°ì¸¡/ìŠ¤ì¼€ì¼ë§/ì¸ì½”ë”© ìˆ˜í–‰
- MachineLearningTool: ì¶”ì²œ ëª¨ë¸ í•™ìŠµ/í‰ê°€

ì§€ì¹¨:
1) íˆ´ì´ í•„ìš”í•œ ì§ˆë¬¸ì´ë©´ í•´ë‹¹ íˆ´ì„ í˜¸ì¶œí•´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
2) ì›ì‹œ JSONì€ ë¤í”„í•˜ì§€ ë§ê³  **í•œêµ­ì–´** ìš”ì•½ìœ¼ë¡œ ì „í™˜í•˜ì„¸ìš”.
3) ìƒì„±ëœ íŒŒì¼ ê²½ë¡œëŠ” ë°±ì—”ë“œê°€ UIì— ë¿Œë¦½ë‹ˆë‹¤.
4) ëª¨í˜¸í•˜ë©´ ê°„ë‹¨íˆ ê°€ì •í•˜ê³  ì§„í–‰í•˜ì„¸ìš”.
`;

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function main() {
  // ì¸ì íŒŒì‹±
  // ì‚¬ìš© ì˜ˆ) ts-node src/main.ts --mode=workflow "ë¶„ì„í•´ì¤˜" /path/to.csv sessionA
  //       ë˜ëŠ” ts-node src/main.ts --mode=chat "í’ˆì§ˆì— ì˜í–¥ í° ë³€ìˆ˜?"
  const args = process.argv.slice(2);
  const modeArgIdx = args.findIndex(a => a.startsWith("--mode="));
  const mode = modeArgIdx >= 0 ? args[modeArgIdx].split("=")[1] : "chat"; // ê¸°ë³¸ chat
  const rest = args.filter((_, i) => i !== modeArgIdx);

  const userMessage = rest[0] || "";
  const csvFilePath = rest[1];
  const argSession = rest[2];
  const sessionId = rest[2];     // FastAPIì—ì„œ ì „ë‹¬ëœ sessionId
  console.log(sessionId)
  const sessionKey = argSession || (csvFilePath ? `local:${csvFilePath}` : "local:default");
  const histories = loadHistories(sessionKey);

  const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

  const agent = new Agentica({
    model: "chatgpt",
    vendor: { model: "gpt-4.1-mini", api: openai },
    controllers: [
      {
        name: "ê¸°ì´ˆ ë¶„ì„ ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<BasicAnalysisTool, "chatgpt">(),
        execute: new BasicAnalysisTool(),
      },
      {
        name: "ì»¬ëŸ¼ ì„ íƒ ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<SelectorTool, "chatgpt">(),
        execute: new SelectorTool(),
      },
      {
        name: "ì „ì²˜ë¦¬ ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<PreprocessingTool, "chatgpt">(),
        execute: new PreprocessingTool(),
      },
      {
        name: "ì‹œê°í™” ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<VisualizationTool, "chatgpt">(),
        execute: new VisualizationTool(),
      },
      {
        name: "ë¨¸ì‹ ëŸ¬ë‹ ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<MachineLearningTool, "chatgpt">(),
        execute: new MachineLearningTool(),
      },
      {
        name: "ìƒê´€ê´€ê³„ ë„êµ¬",
        protocol: "class",
        application: typia.llm.application<CorrelationTool, "chatgpt">(),
        execute: new CorrelationTool(),
      },                
      // CorrelationTool ì‚¬ìš© ì‹œ controllersì— ì¶”ê°€
    ],
    histories,
  });

  // â”€â”€ REPL ë³´ì¡°
    // REPL ëª¨ë“œ
  if (process.argv.includes("--interactive")) {
    const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
    const ask = () => rl.question("> ", async (line) => {
      const prompt = `### SYSTEM\n${CHAT_SYSTEM}\n\n### USER\n(ì•„ë˜ ì§ˆë¬¸ì— í•œêµ­ì–´ë¡œë§Œ ë‹µí•˜ì„¸ìš”)\n${line}`;
      const answers = await agent.conversate(prompt);
      saveHistories(sessionKey, answers);
      for (const ans of answers) if ("text" in ans && ans.text) {
        let out = ans.text;
        if (!isMostlyKorean(out)) out = await forceKoreanOnly(openai, out);
        console.log(out);
      }
      ask();
    });
    console.log(`ğŸ—‚ sessionKey=${sessionKey}`);
    return ask();
  }


  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ëª¨ë“œ ë¶„ê¸°
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  if (mode === "workflow") {
    // ì›Œí¬í”Œë¡œ ëª¨ë“œ: ë§ˆì»¤ JSON í•œ ë²ˆë§Œ ì¶œë ¥
    if (!csvFilePath) throw new Error("workflow ëª¨ë“œì—ëŠ” CSV ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.");

    // (ì„ íƒ) íŒŒì¼ í™•ì¸
    try { fs.readFileSync(csvFilePath, "utf-8"); } catch { /* ignore */ }

    const workflow = new WorkflowTool();
    const result = await workflow.run({ filePath: csvFilePath , sessionId});

    // FastAPIê°€ íŒŒì‹±í•  ìœ ì¼í•œ stdout
    console.log("<<<WORKFLOW_JSON_START>>>");
    console.log(JSON.stringify({ workflow: result }));
    console.log("<<<WORKFLOW_JSON_END>>>");
    return;
  }

  // ê¸°ë³¸: chat ëª¨ë“œ
  {
    let prompt = `### SYSTEM\n${CHAT_SYSTEM}\n\n### USER\n(ì•„ë˜ ìš”ì²­ì— í•œêµ­ì–´ë¡œë§Œ ë‹µí•˜ì„¸ìš”)\n${userMessage}`;
    if (csvFilePath) prompt += `\n\n### CONTEXT\nCSV_FILE_PATH=${csvFilePath}`;

    const answers = await agent.conversate(prompt);
    saveHistories(sessionKey, answers);

    for (const ans of answers) if ("text" in ans && ans.text) {
      let out = ans.text;
      if (!isMostlyKorean(out)) out = await forceKoreanOnly(openai, out);
      console.log(out);
    }
  }

}

main().catch(console.error);
